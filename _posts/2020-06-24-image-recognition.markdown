---
layout: post
title:  "Image Recognition"
date:   2020-06-24 10:05:00 +0100
categories: project upload
---

### Overview

It has become apparent that Neural Networks are exceptionally well-suited for Image Recognition tasks, which is of great importance for Facial Recognition, Driverless Cars, and general Robotics.
Neural Networks are very capable of identifying specific features within an image, and adjusting internal weights and biases according to the relative importance of these features in identifying thee image correctly.

The MNIST hand-written digit dataset is an ideal starting point for learning some of thee concepts behind Neural Networks and Image Recognition. The training dataset is comprised of 42,000 labelled hand-written digits, stored as 28x28 greyscale images.

### Preparation

#### Data Structure

The training and test data exist as .csv files: with each row representing an individual image and the 785 columns representing the pixel values - with 1 column acting as the image label. It is necessary to isolate the target label from the training data prior to preparation. It is also necessary to convert tthe target variables to a cattegorical value, such that each outcome can exist as an individual neuron in the final prediction layer of the network.

{% highlight python %}

# Load data

dfTrain = pd.read_csv('{}/train.csv'.format(DATA_FILEPATH))
yTrain = dfTrain['label']
dfTrain.drop(columns = 'label', inplace = True)
TrainIndex = dfTrain.index

dfTest = pd.read_csv('{}/test.csv'.format(DATA_FILEPATH))
OriginalTestIndex = dfTest.index
dfTest.index += (dfTrain.index.max() + 1)
TestIndex = dfTest.index

# Convert labels to categorical

NumClasses = len(yTrain.unique())
y = keras.utils.to_categorical(yTrain, num_classes = NumClasses)

{% endhighlight %}

#### Reshaping

Subsequently, it is useful to reshape the raw data into a format appropriate for inputting to the network. In this case, the raw data can be reshaped into an "array of arrays", with each sub-array corresponding to one 28x28 greyscale image. As a result, only 1 channel is necessary, as opposed to the 3 channels occupied by RGB images.

{% highlight python %}

def DataPrep(df):

    NumImages = df.shape[0]
    Array = df.values

    Array = Array.reshape(NumImages, NUM_COLS, NUM_ROWS, 1)
    Array = Array / 255

    return Array

{% endhighlight %}

It should be noted that the greyscale pixel values are divided by 255 (the maximum possible value) for normalisation purposes: such that each pixel value exists on a scale between 0 and 1. This is not strictly necessary for this task, although this is a useful concept in some other tasks to prevent inputs from certain sensors overpowering those from other sensors which produce lower absolute values.

### Modelling

I chose to use Keras' sequential model for this task. It is relatively simple in comparison to other Neural Network structures, and is described as being a "Linear stack of layers" by the library's documentation. Layers can be added individually to such a model:

{% highlight python %}

"""
BuildModel: A function to build and compile the neural network
"""

def BuildModel():

    Model = Sequential()

    Model.add(Conv2D(20, kernel_size = (3,3), activation = 'relu',
                     input_shape = (NUM_COLS, NUM_ROWS, 1)))
    Model.add(Conv2D(20, kernel_size = (3,3), activation = 'relu'))
    Model.add(Flatten())
    Model.add(Dense(28, activation = 'relu'))
    Model.add(Dense(NumClasses, activation = 'softmax'))

    Model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',
                  metrics = ['accuracy'])

    return Model

{% endhighlight %}

#### Convolution Layers

A convolution layer applies a distortion or convolution to a small area of the image, which produces a tensor output. These are very useful for identifying small features which make up larger shapes and objects within the image: such as lines and curves.

-**filters:** The number of different feature detection mechanisms applied to the image. In example above, both convolution layers use 20 filters.
- **kernel_size:** The size of the convolution grid in pixels. A 3x3 convolution as used above will only be able to identify very basic features such as edges.
- **activation:** The activation mechanism for neurons within the layer. Rectified Linear Unit (relu) activation signifies that the neuron will not activate until a certain threshold is reached, after which point its output will scale linearly with the input of the neuron.
- **input_shape:** The input shape, equal to the output shape of the previous layer. This must be specified for the first layer of the network, but can be inferred subsequent to this.

#### Flatten Layers

These are used to flatten feature maps generated by convolution layers into a single column that can be passed to fully-connected layers in the network.

#### Dense Layers

Dense layers are "fully connected", such that each neuron is connected to every neuron from the previous layer. During creation of a dense layer, the shape of the output must be specified as well as the activation function to be used.

The final prediction layer exists as a dense layer: with the shape of the output being equal to the number of different image labels. In this layer the "softmax" function is used,
